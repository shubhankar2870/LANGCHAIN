{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x11d31ec10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x11d32c940>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Shubhankar,\\n\\nIt's great to meet you! \\n\\nData science is an exciting field with lots of opportunities. What aspects of data science are you most interested in? \\n\\nI can help you explore different areas like:\\n\\n* **Machine learning algorithms:**  Do you want to learn about supervised learning, unsupervised learning, or reinforcement learning?\\n* **Data visualization:** Are you passionate about creating insightful and engaging visualizations?\\n* **Data cleaning and preprocessing:**  Do you enjoy working with messy data and transforming it into a usable format?\\n* **Specific applications:** Are you interested in using data science for natural language processing, computer vision, or something else?\\n\\nTell me more about your goals and interests, and I can offer more specific advice and resources. Good luck on your journey to becoming a data scientist!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 172, 'prompt_tokens': 24, 'total_tokens': 196, 'completion_time': 0.312727273, 'prompt_time': 0.00017981, 'queue_time': 0.0129222, 'total_time': 0.312907083}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bb7a7b08-366d-4bc0-b45c-4e4ce3e4c436-0', usage_metadata={'input_tokens': 24, 'output_tokens': 172, 'total_tokens': 196})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Shubhankar and I am an aspiring data scientist\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Shubhankar and you are an aspiring data scientist.  \\n\\nIs there anything else you'd like to tell me about your interests or goals?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 453, 'total_tokens': 491, 'completion_time': 0.069090909, 'prompt_time': 0.014761777, 'queue_time': 0.002927902999999999, 'total_time': 0.083852686}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-46a19410-c869-4af1-8c8d-2922652b3596-0', usage_metadata={'input_tokens': 453, 'output_tokens': 38, 'total_tokens': 491})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Shubhankar and I am an aspiring data scientist\"),\n",
    "    AIMessage(content=\"\"\"AIMessage(content=\"Hi Shubhankar, \\n\\nIt's great to meet you!  \\n\\nBeing an aspiring data scientist is an exciting journey. What aspects of data science are you most interested in?  Do you have any specific projects or areas you're looking to explore? \\n\\nI can help you with:\\n\\n* **Understanding different data science concepts:**  I can explain things like machine learning algorithms, data visualization techniques, and statistical modeling.\\n* **Finding resources for learning:** I can point you towards online courses, books, and communities that can help you develop your skills.\\n* **Brainstorming project ideas:** If you're stuck on what to work on, I can help you generate some ideas based on your interests.\\n\\nI'm here to support you on your data science journey.  Let me know how I can help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 24, 'total_tokens': 199, 'completion_time': 0.318181818, 'prompt_time': 0.000156389, 'queue_time': 0.01430011, 'total_time': 0.318338207}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7fdeb470-6ce1-4882-b1f8-5f5307620ec9-0', usage_metadata={'input_tokens': 24, 'output_tokens': 175, 'total_tokens': 199})\"\"\"),\n",
    "    HumanMessage(content=\"What's my name and what do I do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_hisory at 0x11d289dc0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_hisory(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_hisory)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Shubhankar, it's great to meet you!  \\n\\nIt's awesome that you're interested in data science. It's a really exciting field with lots of opportunities. \\n\\nWhat aspects of data science are you most interested in?  Do you have any specific projects you're working on or areas you'd like to learn more about?  \\n\\nI can help you with:\\n\\n* **Understanding different data science concepts:**  From machine learning algorithms to data visualization techniques.\\n* **Finding resources for learning:**  There are tons of online courses, books, and communities dedicated to data science.\\n* **Brainstorming project ideas:**  If you're stuck on what to work on, I can help you come up with some interesting projects.\\n* **Getting feedback on your work:**  If you're working on a project, I can give you feedback on your code or analysis.\\n\\nJust let me know how I can help you on your data science journey!\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is Shubhankar and I am an aspiring data scientist\")], config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Shubhankar.  😊  \\n\\nI remember!  It's nice to meet you, Shubhankar. \\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 247, 'total_tokens': 279, 'completion_time': 0.058181818, 'prompt_time': 0.009593405, 'queue_time': 0.004134094000000001, 'total_time': 0.067775223}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-75eb6d9e-0d2f-4f56-958c-077a6af65dc2-0', usage_metadata={'input_tokens': 247, 'output_tokens': 32, 'total_tokens': 279})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name?\")], config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and don't know your name.  \\n\\nIf you'd like to tell me your name, I'd be happy to use it! 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 15, 'total_tokens': 62, 'completion_time': 0.085454545, 'prompt_time': 7.939e-05, 'queue_time': 0.01451942, 'total_time': 0.085533935}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0615cfc0-163f-42dc-bfa0-30211998b2df-0', usage_metadata={'input_tokens': 15, 'output_tokens': 47, 'total_tokens': 62})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Change the config --> session_id\n",
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name?\")], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is John\")], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is John. 😊 \\n\\nI remember!  \\n\\nDo you have any other questions for me, John?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 117, 'total_tokens': 144, 'completion_time': 0.049090909, 'prompt_time': 0.003906746, 'queue_time': 0.010298743999999999, 'total_time': 0.052997655}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c902be0e-7c6a-4c5d-a600-9f00b9fa121c-0', usage_metadata={'input_tokens': 117, 'output_tokens': 27, 'total_tokens': 144})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name\")], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Shubhankar.  I remember! 😄 \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 291, 'total_tokens': 318, 'completion_time': 0.049090909, 'prompt_time': 0.015251985, 'queue_time': 0.0027891750000000014, 'total_time': 0.064342894}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ec83ce77-a8d8-4012-b6d4-54ea7eb61a4b-0', usage_metadata={'input_tokens': 291, 'output_tokens': 27, 'total_tokens': 318})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name\")], config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Shubhankar! \\n\\nIt's nice to meet you.  \\n\\nHow can I help you today? 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 33, 'total_tokens': 63, 'completion_time': 0.054545455, 'prompt_time': 0.000333268, 'queue_time': 0.013964081000000001, 'total_time': 0.054878723}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4de1dc1e-e10b-4bf9-b113-7d59fd0c240d-0', usage_metadata={'input_tokens': 33, 'output_tokens': 30, 'total_tokens': 63})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"Hi, my name is Shubhankar\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_hisory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is Shubhankar\")], config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Shubhankar, it's nice to meet you! \\n\\nWhat can I do for you today?  😊  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 33, 'total_tokens': 62, 'completion_time': 0.052727273, 'prompt_time': 0.000546538, 'queue_time': 0.013623311, 'total_time': 0.053273811}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-17c5758f-a5fe-4309-b4e0-579d4ea46e82-0', usage_metadata={'input_tokens': 33, 'output_tokens': 29, 'total_tokens': 62})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more complex\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते शुभंकर! \\n\\nआपका नाम शुभंकर है। यह सच है। \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 35, 'total_tokens': 65, 'completion_time': 0.054545455, 'prompt_time': 0.000364349, 'queue_time': 0.013985601, 'total_time': 0.054909804}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b19f7ebf-b849-400e-b7de-7e3512c6af45-0', usage_metadata={'input_tokens': 35, 'output_tokens': 30, 'total_tokens': 65})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"Hi, my name is Shubhankar\")], \"language\": \"hindi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing conversation chat history\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "\n",
    "`trim_messages` helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked \"what\\'s 2 + 2\".  \\n\\nDo you want to try another one? 😊 \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 86, 'total_tokens': 113, 'completion_time': 0.049090909, 'prompt_time': 0.004891403, 'queue_time': 0.009333695999999999, 'total_time': 0.053982312}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6dbb5086-5f1c-47d5-84bd-2973c648ffe3-0', usage_metadata={'input_tokens': 86, 'output_tokens': 27, 'total_tokens': 113})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "    \"messages\": messages + [HumanMessage(content=\"what math problem did I asked\")],\n",
    "    \"language\": \"english\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's wrap this in the message history\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_hisory,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history(\n",
    "    {\n",
    "        \"messages\": HumanMessage(content=\"what math problem did I asked?\"),\n",
    "        \"language\": \"english\" \n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
